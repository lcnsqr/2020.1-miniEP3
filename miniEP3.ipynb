{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniEP3 - Aproximação de Integrais usando Médias e Amostragem Uniforme, com a biblioteca *pthreads*\n",
    "\n",
    "## Entrega do miniEP3\n",
    "\n",
    "Preencha o nome dos 5 membros do seu grupo na tabela abaixo:\n",
    "\n",
    "| Nome | NUSP |\n",
    "|------|------|\n",
    "| Guilherme Lamartine de Mello | 9046046 |\n",
    "| Luciano Antonio Siqueira | 8535467 |\n",
    "| Ronaldo Nogueira de Sousa | 11853569 |\n",
    "| Aarão Melo Lopes | 11347794 |\n",
    "| Laira das Almas Silva | 11179870 |\n",
    "\n",
    "**Apenas um dos membros** deverá entregar um **arquivo .tar**, até o dia **29 de Abril**, com:\n",
    "\n",
    "1. **Este arquivo** `.ipynb`, com as soluções do miniEP3 **feitas pelo grupo**\n",
    "    \n",
    "    - Os gráficos e análises devem poder ser produzidos\n",
    "    \n",
    "    \n",
    "2. O **código C escrito** (arquivo `monte_carlo.c`)\n",
    "\n",
    "    - Deve compilar e executar **sem erros**\n",
    "    \n",
    "    \n",
    "    \n",
    "3. Os arquivos `Makefile`, e `Project.toml`\n",
    "4. Um **arquivo .csv** com os resultados das medições feitas neste miniEP\n",
    "\n",
    "    - Entregue os dados de cada repetição, sem processamento (não calcule a média e CI)\n",
    "\n",
    "## Configuração do Ambiente\n",
    "\n",
    "Como no miniEP1&2, a primeira tarefa é instalar e configurar o ambiente.\n",
    "\n",
    "### Compilador C\n",
    "\n",
    "Neste miniEP também vamos usar a linguagem C e a biblioteca *pthreads*. Vocês vão precisar de acesso a um sistema Linux com o compilador GCC e a biblioteca *pthreads*. Caso não consiga instalar o GCC ou tenha dificuldades para acessar um sistema Linux, entre em contato pelo fórum do *Edisciplinas*.\n",
    "\n",
    "### Julia, Jupyter, IJulia\n",
    "\n",
    "Pule essa etapa se já configurou o ambiente Julia no miniEP1&2.\n",
    "Para fazer o miniEP, vocês vão precisar:\n",
    "\n",
    "- [Instalar o Jupyter Notebook](https://jupyter.readthedocs.io/en/latest/install.html)\n",
    "- Instalar Julia 1.3:\n",
    "    - [Baixando o binário](https://julialang.org/downloads/)\n",
    "    - **ou** [usando seu gerenciador de pacotes](https://julialang.org/downloads/platform/)\n",
    "- Instalar o pacote *IJulia*:\n",
    "    - Inicie o interpretador Julia\n",
    "    - Digite `] add IJulia` e pressione `<ENTER>`\n",
    "    \n",
    "Depois disso, vocês vão conseguir iniciar o arquivo `.ipynb` do miniEP.\n",
    "\n",
    "### Pacotes Julia para o miniEP\n",
    "\n",
    "Os pacotes necessários para o miniEP estão listados no arquivo `Project.toml`, mas vocês podem instalar e atualizar os pacotes rodando a célula abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "] up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique o status dos pacotes, e se há algum problema, com o comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "] st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integração por Método de Monte Carlo\n",
    "\n",
    "O objetivo deste miniEP é promover o estudo de programação paralela usando a biblioteca *pthreads*. Vamos utilizar uma versão sequencial em C do código em Julia do miniEP1&2. A tarefa deste miniEP será completar a implementação em C, escrever um programa paralelo usando a biblioteca *pthreads*, e analisar o desempenho do programa escrito com diferentes números de threads.\n",
    "\n",
    "Lembrando o que vimos no miniEP1&2, a intuição por trás do método de Monte Carlo é que a integral de uma função $f$ pode ser estimada pela média do valor de $f$ num conjunto suficientemente grande de pontos obtidos a partir de uma distribuição uniforme. Mais formalmente, para um conjunto de pontos $x_1,\\dots,x_N$ uniformemente amostrados num intervalo $[a,b]$, a integral de $f$ no intervalo $[a,b]$ pode ser aproximada por:\n",
    "\n",
    "$$\n",
    "\\int_{a}^{b} f(x)dx \\approx \\mathbb{E}\\left[\\left(b - a\\right)\\dfrac{1}{N}\\sum\\limits_{i = 1}^{N}{f(x_i)}\\right] \n",
    "$$\n",
    "\n",
    "Para uma representação gráfica da intuição, e para a prova dessa aproximação, veja [esta página](https://www.scratchapixel.com/lessons/mathematics-physics-for-computer-graphics/monte-carlo-methods-in-practice/monte-carlo-integration).\n",
    "\n",
    "A Integração por Método de Monte Carlo é um problema [embaraçosamente paralelo](https://en.wikipedia.org/wiki/Embarrassingly_parallel), isto é, podemos executar todas as iterações envolvidas **em paralelo**, sem nos preocupar com conflitos de acesso à memória. Apesar disso, vamos ver neste miniEP que não basta apenas aumentar a quantidade de recursos computacionais para ganhar desempenho.\n",
    "\n",
    "### Função Alvo\n",
    "\n",
    "Vamos estimar a integral da seguinte função:\n",
    "\n",
    "$$\n",
    "f_1(x) = \\dfrac{2}{\\sqrt{1 - x ^ 2}}\n",
    "$$\n",
    "\n",
    "A integral da função $f_1$, é [dada por](https://en.wikipedia.org/wiki/List_of_definite_integrals#Definite_integrals_involving_rational_or_irrational_expressions):\n",
    "\n",
    "$$\n",
    "\\int_{0}^{1}{f_1(x)dx} = \\int_{0}^{1}{\\dfrac{2}{\\sqrt{1 - x ^ 2}}dx} = \\pi\n",
    "$$\n",
    "\n",
    "## Exercício 1: Implementação Sequencial em C\n",
    "\n",
    "Lembre-se do código em Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "\n",
    "function monte_carlo_integrate(f, interval, samples = 100)\n",
    "    xs = rand(Uniform(interval[1], interval[2]), samples)\n",
    "    \n",
    "    # Using for loops:\n",
    "    # accumulator = 0\n",
    "    #\n",
    "    # for x in xs\n",
    "    #     accumulator += f(x)\n",
    "    # end\n",
    "    #\n",
    "    # return accumulator / samples\n",
    "    \n",
    "    # Using vectorized function application:\n",
    "    return sum(f.(xs)) / samples\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro exercício consiste em completar a implementação sequencial em C, fornecida no arquivo `monte_carlo.c`. Baseiem-se na versão Julia, e usem seus editores de código preferidos para modificar e escrever código em C. Se vocês ainda não têm preferência de editor de código, procurem experimentar editores como o Emacs e o Vim. São programas antigos e com uma curva de aprendizado um pouco íngreme, mas são muito poderosos e os esforços se pagam com juros. Esta pode ser uma chance de aprender a usá-los.\n",
    "\n",
    "Vocês devem escrever a função de assinatura:\n",
    "\n",
    "```C\n",
    "long double monte_carlo_integrate(long double (*f)(long double), long double *samples, int size)\n",
    "```\n",
    "\n",
    "Na assinatura acima, o parâmetro `f` é um ponteiro para uma função que recebe um `long double` e devolve um `long double`, `samples` é um ponteiro para um vetor de `long double` onde vamos guardar os valores de `f` que queremos avaliar, e `size` é o tamanho de `samples`.\n",
    "\n",
    "A primeira parte do exercício é ler e compreender o funcionamento do código em C fornecido no enunciado. É um exercício interessante para ver como uma linguagem de alto nível, como Julia, abstrai camadas conceituais e facilita a prototipagem de código complexo ao custo de esconder detalhes de implementação.\n",
    "\n",
    "### Exercício 1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocês podem compilar e executar o programa `monte_carlo.c` através deste notebook acessando o *modo shell* do interpretador Julia com a tecla `;`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc monte_carlo.c -o monte_carlo -Wall -lpthread -lm -DDEBUG=1\n"
     ]
    }
   ],
   "source": [
    "; make debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, podemos rodar o programa compilado com:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./monte_carlo SAMPLES FUNCTION_ID N_THREADS\n"
     ]
    }
   ],
   "source": [
    "; ./monte_carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguindo as instruções de uso, temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: [debug mode]\n",
      "Samples: [10000000]\n",
      "Function id: [0]\n",
      "Threads: [1]\n",
      "Array size on memory: [0.16GB]\n",
      "Running sequential version\n",
      "3.1446820234388172, [0.325617, clock], [0.325639, clock_gettime], [0.325637, gettimeofday]\n"
     ]
    }
   ],
   "source": [
    "; ./monte_carlo 10000000 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como compilamos no modo *debug*, veremos muitas mensagens extras, que coloquei no programa pra ajudar na implementação. Para compilar no modo normal, use o comando `make` sem argumentos. Note que o programa ainda não faz nada além de alocar memória, e que isso já leva algum tempo.\n",
    "\n",
    "Note que escolhi deixar a alocação de memória e o cálculo das amostra a avaliar fora da função `monte_carlo_integrate` na versão C. A geração das amostras aleatórias foi feita com a função `rand()` e com uma função que mapeia um intervalo a outro.\n",
    "\n",
    "\n",
    "Descreva abaixo como o tempo de execução é calculado e impresso pelo programa `monte_carlo`. Por que vocês acham que eu escolhi colocar as medições de tempo onde coloquei?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `clock()` informa quantos ciclos de CPU foram utilizados, por isso a medida em segundos é gerada dividindo o intervalo pela constante `CLOCKS_PER_SEC`. A função `clock_gettime()` baseia-se no relógio da máquina, com precisão de nanosegundos. O tempo informado por ela inclui eventuais ocilações graduais feitas por programas que ajustam o relógio automaticamente (como o cliente NTP), mas desconsidera descontinuidades. Quando usada com `CLOCK_MONOTONIC`, eventuais ajustes retrocedendo o relógio são desconsiderados. Já a função `gettimeofday()` dá a contagem mais familiar do tempo, pois vai considerar qualquer alteração ocorrida no relógio da máquina enquanto o program foi executado (com precisão de microsegundos).\n",
    "\n",
    "O início e o fim das medições foram posicionados imediatamente antes e depois do trecho que é responsável por computar a solução. Desse modo, são descartados os tempos de produção e alocação das amostras na memória, assim como o tempo utilizado para outras ações do programa que não estão diretamente relacionadas com a coleta dos dados na memória e seu processamento. Essa estratégia permite avaliar com maior precisão qual é o impacto no tempo de execução ao dividir ao dividir o processamento em mais de um thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1b)\n",
    "\n",
    "Agora, a sua tarefa é implementar a função `monte_carlo_integrate`.\n",
    "\n",
    "Quando terminar, rode as células abaixo. A saída deve conter a estimativa para o valor de $\\pi$ e o tempo de execução, produzidos pelo programa `monte_carlo`. Escolha um número de amostras adequado à quantidade de memória disponível em seu computador.\n",
    "\n",
    "Lembre-se de **entregar também o arquivo .c** com suas modificações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc monte_carlo.c -o monte_carlo -Wall -lpthread -lm -DDEBUG=1\n"
     ]
    }
   ],
   "source": [
    "; make debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: [debug mode]\n",
      "Samples: [100000000]\n",
      "Function id: [0]\n",
      "Threads: [1]\n",
      "Array size on memory: [1.60GB]\n",
      "Running sequential version\n",
      "3.1415364173280980, [3.184236, clock], [3.184382, clock_gettime], [3.184381, gettimeofday]\n"
     ]
    }
   ],
   "source": [
    "; ./monte_carlo 100000000 0 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2: Implementação Paralela com *pthreads*\n",
    "\n",
    "Este exercício é mais complexo. Vocês devem escrever a função de assinatura:\n",
    "\n",
    "```C\n",
    "void *monte_carlo_integrate_thread(void *args)\n",
    "```\n",
    "\n",
    "Na assinatura acima, o parâmetro `args` é um ponteiro para uma estrutura de dados contendo dados para cada thread. Para implementar essa estrutura de dados, vocês devem decidir quais informações cada thread deve receber. Algumas ideias:\n",
    "\n",
    "- Um ponteiro para a função a ser avaliada\n",
    "- Um ponteiro para o vetor de amostras gerado\n",
    "- Um inteiro com o id da thread\n",
    "\n",
    "De acordo com a sua estratégia de implementação paralela, vocês vão precisar incluir informações diferentes. Algo de importante está faltando na lista acima. Como as threads poderiam armazenar seus resultados?\n",
    "\n",
    "Precisamos escolher uma dentre as várias formas de implementar esse algoritmo paralelo. Pensei em algumas possibilidades:\n",
    "\n",
    "1. Método \"Criando threads dinamicamente\":\n",
    "  - Lançar $n$ threads, cada uma com $1$ (ou $m$?) unidades de trabalho a fazer\n",
    "  - Usar variáveis de condição ou joins para sinalizar fim de trabalho\n",
    "  - Lançar novas threads conforme threads terminarem\n",
    "  - Usar join para finalizar\n",
    "2. Método \"Divisão Dinâmica do Trabalho\":\n",
    "  - Lançar $n$ threads, cada uma com $1$ (ou $m$?) unidades de trabalho a fazer\n",
    "  - Cada thread busca por trabalho disponível a fazer quando acabar o trabalho dado\n",
    "  - Usar join para finalizar\n",
    "3. Método \"Divisão Estática do Trabalho\":\n",
    "  - Lançar $n$ threads, cada uma com $1/n$ unidades de trabalho a fazer\n",
    "  - Usar join para finalizar\n",
    "  \n",
    "Usando seus conhecimentos sobre *pthreads* e sobre a execução de programas em geral, responda e explique:\n",
    "\n",
    "1. Qual desses métodos é o mais difícil de implementar? E o mais fácil?\n",
    "2. Qual método atingiria o menor tempo de execução?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O primeiro método é mais difícil de implementar, pois exige variáveis auxiliares de controle e o disparo dinâmico de threads ao longo da execução do programa. O segundo método, apesar de mais simples que o primeiro, também atribui aos threads a tarefa adicional de verificar o estado geral do problema para desempenhar sua tarefa específica. O terceiro método é mais simples, pois nele o número de threads e a carga de trabalho de cada um são definidos no início do programa e permanecem inalterados ao longo da execução.\n",
    "\n",
    "2. Em tese, o terceiro método é o mais rápido, pois dispensa o processamento extra necessário para disparar novas threads e verificar o estados dos demais threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolha um desses, ou um quarto método que preferir, para fazer a implementação paralela do miniEP3. Vocês vão precisar implementar toda a estrutura de suporte à execução das threads.\n",
    "\n",
    "Quando terminar, rode as células abaixo. A saída deve conter a estimativa para o valor de $\\pi$ e o tempo de execução, produzidos pelo programa `monte_carlo`. Escolha um número de amostras e de threads adequado à quantidade de memória e aos núcleos de processamento disponíveis em seu computador.\n",
    "\n",
    "Lembre-se de **entregar também o arquivo .c** com suas modificações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc monte_carlo.c -o monte_carlo -Wall -lpthread -lm -DDEBUG=1\n"
     ]
    }
   ],
   "source": [
    "; make debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: [debug mode]\n",
      "Samples: [800000000]\n",
      "Function id: [0]\n",
      "Threads: [80]\n",
      "Array size on memory: [12.80GB]\n",
      "Running parallel version\n",
      "3.1415048916187272, [117.030702, clock], [20.990709, clock_gettime], [20.990708, gettimeofday]\n"
     ]
    }
   ],
   "source": [
    "; ./monte_carlo 800000000 0 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3: Análise de Desempenho\n",
    "\n",
    "Agora, vamos medir o desempenho do programa que vocês implementaram neste trabalho. Vamos usar funções em Julia, adaptadas do miniEP1&2, e gerar gráficos do tempo de execução e da estimativa da integral para diferentes números de threads.\n",
    "\n",
    "### Funções Úteis\n",
    "\n",
    "A função abaixo recebe parâmetros `size`, com tamanho da amostra, `f`, com a id da função a estimar, e `threads`, com o número de threads do programa paralelo. A função executa o programa `monte_carlo` com os parâmetros dados e devolve um `DataFrame` com os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "measure_monte_carlo (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames, Query, StatsPlots, Statistics\n",
    "\n",
    "function measure_monte_carlo(size, f, threads)\n",
    "    results = parse.(Float64,\n",
    "        split(chomp(read(`./monte_carlo $size $f $threads`, String)), \", \"))\n",
    "        \n",
    "    return DataFrame(size = size,\n",
    "        f = f,\n",
    "        threads = threads,\n",
    "        estimate = results[1],\n",
    "        duration = results[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `run_experiments` recebe os mesmos parâmetros `size`, `f`, e `threads`, e um parâmetro adicional `repetitions`, com o número de repetições de cada experimento com um dado número de `threads`. A função devolve um `DataFrame` com todos os experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_experiments (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function run_experiments(size, f, threads, repetitions)\n",
    "    run(`make`)\n",
    "    \n",
    "    results = DataFrame(size = Int[],\n",
    "        f = Int[],\n",
    "        threads = Int[],\n",
    "        estimate = Float64[],\n",
    "        duration = Float64[])  \n",
    "    \n",
    "    for t in threads\n",
    "        for r in 1:repetitions\n",
    "            append!(results,\n",
    "                measure_monte_carlo(size, f, t))    \n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `parse_results` recebe um `DataFrame` de resultados, produzido pela função `run_experiments`, e um parâmetro `target_integral`, com o valor da integral a estimar. A função devolve um `DataFrame` com a média e o intervalo de confiança da média a 95% das estimativas e dos tempos de execução, agrupados por número de threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parse_results (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function parse_results(results, target_integral)\n",
    "    parsed_results = results |>\n",
    "                    @groupby(_.threads) |>\n",
    "                    @map({threads = key(_),\n",
    "                          mean_estimate = mean(_.estimate),\n",
    "                          ci_estimate = 1.96 * std(_.estimate),\n",
    "                          mean_duration = mean(_.duration),\n",
    "                          ci_duration = 1.96 * std(_.duration),\n",
    "                          target = target_integral}) |>\n",
    "                    DataFrame\n",
    "    \n",
    "    return parsed_results\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3a)\n",
    "\n",
    "Realize os experimentos em sua máquina rodando a célula abaixo. Ajuste os valores para a sua máquina. **Não faça menos de 5 repetições**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc monte_carlo.c -o monte_carlo -Wall -lpthread -lm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>threads</th><th>mean_estimate</th><th>ci_estimate</th><th>mean_duration</th><th>ci_duration</th><th>target</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Irration…</th></tr></thead><tbody><p>12 rows × 6 columns</p><tr><th>1</th><td>1</td><td>3.14151</td><td>0.00249214</td><td>0.626471</td><td>0.00995209</td><td>π</td></tr><tr><th>2</th><td>2</td><td>3.1411</td><td>0.00305576</td><td>0.736299</td><td>0.0306132</td><td>π</td></tr><tr><th>3</th><td>4</td><td>3.14181</td><td>0.00449793</td><td>0.684194</td><td>0.0185468</td><td>π</td></tr><tr><th>4</th><td>8</td><td>3.14199</td><td>0.000800723</td><td>0.619318</td><td>0.00983829</td><td>π</td></tr><tr><th>5</th><td>16</td><td>3.14118</td><td>0.00398908</td><td>0.559738</td><td>0.00320452</td><td>π</td></tr><tr><th>6</th><td>32</td><td>3.1406</td><td>0.00132712</td><td>0.55739</td><td>0.0133428</td><td>π</td></tr><tr><th>7</th><td>64</td><td>3.14186</td><td>0.00190517</td><td>0.527319</td><td>0.00975129</td><td>π</td></tr><tr><th>8</th><td>128</td><td>3.14092</td><td>0.000480722</td><td>0.51569</td><td>0.0106681</td><td>π</td></tr><tr><th>9</th><td>256</td><td>3.14276</td><td>0.00127085</td><td>0.509528</td><td>0.00459399</td><td>π</td></tr><tr><th>10</th><td>512</td><td>3.14037</td><td>0.00153026</td><td>0.519137</td><td>0.00929053</td><td>π</td></tr><tr><th>11</th><td>1024</td><td>3.1409</td><td>0.00174908</td><td>0.535602</td><td>0.0105728</td><td>π</td></tr><tr><th>12</th><td>2048</td><td>3.1415</td><td>0.00231587</td><td>0.554833</td><td>0.0203095</td><td>π</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& threads & mean\\_estimate & ci\\_estimate & mean\\_duration & ci\\_duration & target\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64 & Float64 & Irration…\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 3.14151 & 0.00249214 & 0.626471 & 0.00995209 & π \\\\\n",
       "\t2 & 2 & 3.1411 & 0.00305576 & 0.736299 & 0.0306132 & π \\\\\n",
       "\t3 & 4 & 3.14181 & 0.00449793 & 0.684194 & 0.0185468 & π \\\\\n",
       "\t4 & 8 & 3.14199 & 0.000800723 & 0.619318 & 0.00983829 & π \\\\\n",
       "\t5 & 16 & 3.14118 & 0.00398908 & 0.559738 & 0.00320452 & π \\\\\n",
       "\t6 & 32 & 3.1406 & 0.00132712 & 0.55739 & 0.0133428 & π \\\\\n",
       "\t7 & 64 & 3.14186 & 0.00190517 & 0.527319 & 0.00975129 & π \\\\\n",
       "\t8 & 128 & 3.14092 & 0.000480722 & 0.51569 & 0.0106681 & π \\\\\n",
       "\t9 & 256 & 3.14276 & 0.00127085 & 0.509528 & 0.00459399 & π \\\\\n",
       "\t10 & 512 & 3.14037 & 0.00153026 & 0.519137 & 0.00929053 & π \\\\\n",
       "\t11 & 1024 & 3.1409 & 0.00174908 & 0.535602 & 0.0105728 & π \\\\\n",
       "\t12 & 2048 & 3.1415 & 0.00231587 & 0.554833 & 0.0203095 & π \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "12×6 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ threads │ mean_estimate │ ci_estimate │ mean_duration │ ci_duration │\n",
       "│     │ \u001b[90mInt64\u001b[39m   │ \u001b[90mFloat64\u001b[39m       │ \u001b[90mFloat64\u001b[39m     │ \u001b[90mFloat64\u001b[39m       │ \u001b[90mFloat64\u001b[39m     │\n",
       "├─────┼─────────┼───────────────┼─────────────┼───────────────┼─────────────┤\n",
       "│ 1   │ 1       │ 3.14151       │ 0.00249214  │ 0.626471      │ 0.00995209  │\n",
       "│ 2   │ 2       │ 3.1411        │ 0.00305576  │ 0.736299      │ 0.0306132   │\n",
       "│ 3   │ 4       │ 3.14181       │ 0.00449793  │ 0.684194      │ 0.0185468   │\n",
       "│ 4   │ 8       │ 3.14199       │ 0.000800723 │ 0.619318      │ 0.00983829  │\n",
       "│ 5   │ 16      │ 3.14118       │ 0.00398908  │ 0.559738      │ 0.00320452  │\n",
       "│ 6   │ 32      │ 3.1406        │ 0.00132712  │ 0.55739       │ 0.0133428   │\n",
       "│ 7   │ 64      │ 3.14186       │ 0.00190517  │ 0.527319      │ 0.00975129  │\n",
       "│ 8   │ 128     │ 3.14092       │ 0.000480722 │ 0.51569       │ 0.0106681   │\n",
       "│ 9   │ 256     │ 3.14276       │ 0.00127085  │ 0.509528      │ 0.00459399  │\n",
       "│ 10  │ 512     │ 3.14037       │ 0.00153026  │ 0.519137      │ 0.00929053  │\n",
       "│ 11  │ 1024    │ 3.1409        │ 0.00174908  │ 0.535602      │ 0.0105728   │\n",
       "│ 12  │ 2048    │ 3.1415        │ 0.00231587  │ 0.554833      │ 0.0203095   │"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 20000000\n",
    "f = 0\n",
    "threads = [2 ^ x for x in 0:11]\n",
    "repetitions = 5\n",
    "\n",
    "results = run_experiments(size, f, threads, repetitions)\n",
    "parsed_results = parse_results(results, pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, escreva uma função **em Julia** chamada `save_csv_results`, que recebe um `DataFrame` e um nome de arquivo, e escreve o `DataFrame` em disco, no formato `.csv`, com o nome passado no argumento.\n",
    "\n",
    "Utilize a biblioteca [CSV](https://juliadata.github.io/CSV.jl/stable/), já instalada no ambiente deste notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"results.csv\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "\n",
    "function save_csv_results(results, filename)\n",
    "    CSV.write(filename, results)\n",
    "end\n",
    "\n",
    "save_csv_results(results, \"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva uma função **em Julia** chamada `read_csv_results`, que recebe um nome de arquivo e lê o arquivo correspondente, devolvendo um `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_csv_results (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "\n",
    "function read_csv_results(filename)\n",
    "    results = CSV.read(filename)\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salve o DataFrame `results` em disco. **Vocês devem entregar o .csv também**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3b)\n",
    "\n",
    "Como vocês já se familiarizaram um pouco com funções para geração de gráficos no miniEP1&2, explique o que faz a função `plot_results` abaixo. Ela é uma generalização das funções usadas no miniEP anterior. Para ajudar, você pode modificar e usar as chamadas de função no **Exercício 3c)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgfplotsx()\n",
    "\n",
    "function plot_results(x, y, target_label, series_label; hline = [], yerror = [], max_thread_power = 10)      \n",
    "    if yerror != []\n",
    "        p = scatter(x,\n",
    "            y,\n",
    "            xaxis = :log2,\n",
    "            xlabel = \"Threads\",\n",
    "            xticks = [2 ^ x for x in 0:max_thread_power],\n",
    "            yerror = yerror,\n",
    "            alpha = 0.6,\n",
    "            labels = series_label,\n",
    "            legend = :topright)\n",
    "    else\n",
    "        p = scatter(x,\n",
    "            y,\n",
    "            xaxis = :log2,\n",
    "            xlabel = \"Threads\",\n",
    "            xticks = [2 ^ x for x in 0:max_thread_power],\n",
    "            alpha = 0.6,\n",
    "            labels = series_label,\n",
    "            legend = :topright)\n",
    "    end\n",
    "    \n",
    "    if hline != []\n",
    "        plot!(x,\n",
    "            hline,\n",
    "            xaxis = :log2,\n",
    "            xlabel = \"Threads\",\n",
    "            xticks = [2 ^ x for x in 0:max_thread_power],\n",
    "            labels = target_label,                             \n",
    "            line = :dash,                    \n",
    "            width = 2.0)\n",
    "    end\n",
    "    \n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3c)\n",
    "\n",
    "1. Rode as células na seção abaixo e gere os gráficos. **Entregue o notebook com os gráficos gerados**.\n",
    "2. Descreva o comportamento do tempo de execução conforme aumentamos o número de threads, em termos da média e do intervalo de confiança. Nos próximos EPs, vamos aprender a fazer uma *regressão linear* que explique os dados observados usando *coeficientes*.\n",
    "3. Por que você acha que o tempo de execução aumenta conforme aumentamos as threads? Era isso que você esperava?\n",
    "\n",
    "Responda na célula abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results.threads,\n",
    "    results.duration,    \n",
    "    \"pi\",\n",
    "    \"Duration\",\n",
    "    max_thread_power = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results.threads,\n",
    "    results.estimate,    \n",
    "    \"pi\",\n",
    "    \"Estimate\",\n",
    "    hline = [pi for i in 1:nrow(results)],\n",
    "    max_thread_power = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(parsed_results.threads,\n",
    "    parsed_results.mean_duration,\n",
    "    \"pi\",\n",
    "    \"Mean Duration + CI\",\n",
    "    yerror = parsed_results.ci_duration,\n",
    "    max_thread_power = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(parsed_results.threads,\n",
    "    parsed_results.mean_estimate,\n",
    "    \"pi\",\n",
    "    \"Mean Estimate + CI\",\n",
    "    hline = [pi for i in 1:nrow(parsed_results)],\n",
    "    yerror = parsed_results.ci_estimate,\n",
    "    max_thread_power = 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
